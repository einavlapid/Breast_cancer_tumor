{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import warnings as datawarnings\n",
    "datawarnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('df_final_feature.pkl')\n",
    "df = pd.read_pickle('df_final_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    int8   \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int8(1)\n",
      "memory usage: 134.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data into train, dev, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['diagnosis'])\n",
    "y = df['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selction\n",
    "\n",
    "Evaluate the performance of four different classification models:\n",
    "\n",
    "SVC, XGBoost, Gradient Boosting, and Random Forest\n",
    "\n",
    "since the data did not follow a normal distribution, models relying on normality assumptions were excluded.\n",
    "\n",
    "Outputs: For each model, it prints:\n",
    "\n",
    "The confusion matrix, which shows the performance of the model in terms of true and false predictions.\n",
    "\n",
    "The classification report, which provides precision, recall, F1-score, and support for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics \n",
    "def classificationMetrics(y, yhat):\n",
    "    prf1 = metrics.precision_recall_fscore_support(y,yhat)\n",
    "    res = {'Accuracy': metrics.accuracy_score(y,yhat),\n",
    "           'Precision':prf1[0][1],\n",
    "           'Recall': prf1[1][1],\n",
    "           'f1-score': prf1[2][1],\n",
    "           'Log-loss': metrics.log_loss(y,yhat),\n",
    "           'AUC': metrics.roc_auc_score(y,yhat)\n",
    "          }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, log_loss, roc_auc_score\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro'),\n",
    "    'f1': make_scorer(f1_score, average='macro'),\n",
    "    'log_loss': make_scorer(log_loss, needs_proba=True),\n",
    "    'auc': make_scorer(roc_auc_score, average='macro', multi_class='ovr')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "model: SVM\n",
      "\n",
      "[[108   0]\n",
      " [ 11  52]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       108\n",
      "           1       1.00      0.83      0.90        63\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.95      0.91      0.93       171\n",
      "weighted avg       0.94      0.94      0.93       171\n",
      "\n",
      "\n",
      "\n",
      "model: XGBoost\n",
      "\n",
      "[[107   1]\n",
      " [  2  61]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       108\n",
      "           1       0.98      0.97      0.98        63\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n",
      "\n",
      "\n",
      "model: Gradient Boosting\n",
      "\n",
      "[[105   3]\n",
      " [  4  59]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       108\n",
      "           1       0.95      0.94      0.94        63\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.95      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "\n",
      "\n",
      "model: Random Forest\n",
      "\n",
      "[[107   1]\n",
      " [  3  60]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       108\n",
      "           1       0.98      0.95      0.97        63\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.97      0.97       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "models = [SVC(), XGBClassifier(), GradientBoostingClassifier(), RandomForestClassifier()]\n",
    "model_names = [\"SVM\", \"XGBoost\", \"Gradient Boosting\", \"Random Forest\"]\n",
    "models_list = pd.DataFrame()\n",
    "for model, name in zip(models, model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    model_dict = {'model': name}\n",
    "\n",
    "    print(f\"\\n\\nmodel: {name}\\n\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print()\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of model selection results\n",
    "Overall Conclusion\n",
    "\n",
    "**XGBoost has the highest overall** accuracy (0.98) and performs consistently well across all metrics (precision, recall, F1-score). It's the most balanced and robust model among the four.\n",
    "SVM has slightly lower recall for Class 1, which could be a concern if capturing all positives in this class is crucial.\n",
    "Gradient Boosting and Random Forest are also strong contenders, both achieving high accuracy and balanced precision and recall. However, they fall slightly short of XGBoost in overall performance.\n",
    "\n",
    "**Recommendation: continue to the next step of hyperparameter tuning with XGBoost and SVC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines Hyperparameter Grids: Specifies ranges of hyperparameters for SVC and XGBoost to be tuned.\n",
    "\n",
    "Uses GridSearchCV: To find the best hyperparameters by evaluating all possible combinations using cross-validation.\n",
    "\n",
    "Evaluates Models: After tuning, the models are evaluated on the test set, and results are printed, including confusion matrices and classification reports, to understand their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Hyperparameter Grids:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],  # Number of trees to build\n",
    "    'max_depth': [3, 4],         # Depth of each tree, generally controls overfitting\n",
    "    'learning_rate': [0.1, 0.2],  # Step size at each iteration, balances learning\n",
    "    'subsample': [0.8, 1.0],     # Fraction of samples to use for training each tree\n",
    "    'colsample_bytree': [0.8, 1.0],  # Fraction of features to use for each tree\n",
    "    'gamma': [0, 0.1],           # Regularization parameter, helps with model complexity\n",
    "    'min_child_weight': [1, 3]   # Minimum sum of instance weight for a child, controls overfitting\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Hyperparameter Tuning:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Tuning\n",
    "svc_cv = GridSearchCV(SVC(),svc_param_grid,refit=True)\n",
    "svc_cv.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve Best Parameters\n",
    "best_svc_params = svc_cv.best_params_\n",
    "best_svc_estimators = svc_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Tuning\n",
    "# xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb = XGBClassifier()\n",
    "xgb_cv = GridSearchCV(xgb, xgb_param_grid, refit=True)\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve Best Parameters\n",
    "best_xgb_params = xgb_cv.best_params_\n",
    "best_xgb_estimators = xgb_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC result:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "SVC(C=100, gamma=0.0001)\n"
     ]
    }
   ],
   "source": [
    "print(\"SVC result:\")\n",
    "print(best_svc_params)\n",
    "print(best_svc_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost result:\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 0.8}\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1.0,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0.1, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.2, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost result:\")\n",
    "print(best_xgb_params)\n",
    "print(best_xgb_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Tuned Models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "model: Tuned_XGBoost\n",
      "\n",
      "\n",
      "Test:\n",
      "[[104   4]\n",
      " [  3  60]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       108\n",
      "           1       0.94      0.95      0.94        63\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.95      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n",
      "\n",
      "\n",
      "model: XGBoost\n",
      "\n",
      "\n",
      "Test:\n",
      "[[107   1]\n",
      " [  2  61]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       108\n",
      "           1       0.98      0.97      0.98        63\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n",
      "\n",
      "\n",
      "model: Tuned_SVC\n",
      "\n",
      "\n",
      "Test:\n",
      "[[106   2]\n",
      " [  6  57]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       108\n",
      "           1       0.97      0.90      0.93        63\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.96      0.94      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n",
      "\n",
      "\n",
      "model: SVC\n",
      "\n",
      "\n",
      "Test:\n",
      "[[108   0]\n",
      " [ 11  52]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       108\n",
      "           1       1.00      0.83      0.90        63\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.95      0.91      0.93       171\n",
      "weighted avg       0.94      0.94      0.93       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_models = [xgb_cv, XGBClassifier(), svc_cv, SVC()]\n",
    "tuned_model_names = [\"Tuned_XGBoost\",\"XGBoost\", \"Tuned_SVC\", \"SVC\"] \n",
    "tuned_models_list = pd.DataFrame()\n",
    "for model, name in zip(tuned_models, tuned_model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n\\nmodel: {name}\\n\")\n",
    "    print(f\"\\nTest:\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print()\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning results\n",
    "\n",
    "**XGBoost (not tuned)**\n",
    "\n",
    "**shows the best overall performance** with high accuracy, precision, recall, and F1-scores for both classes. It appears to generalize well and could be the preferred model if you want high performance across the board.\n",
    "\n",
    "**Tuned XGBoost** \n",
    "\n",
    "performs slightly worse than the not-tuned version, which suggests that the tuning might not have been effective.\n",
    "\n",
    "**Tuned SVC** \n",
    "\n",
    "shows improvements over the untuned version and performs quite well, especially in precision for class 1. However, it has slightly lower recall for class 1 compared to the XGBoost models.\n",
    "\n",
    "**SVC (not tuned)**\n",
    "\n",
    "has lower overall performance, especially in terms of recall for malignant cases, which could be a concern in medical diagnostics.\n",
    "Recommendations\n",
    "\n",
    "**XGBoost (not tuned) appears to be the most robust model, achieving the highest accuracy and balanced performance metrics. Consider using this model if maximizing overall performance is the goal.**\n",
    "\n",
    "Tuned XGBoost and Tuned SVC both offer good performance but with slightly different strengths and weaknesses.\n",
    "Depending on your focus (e.g., precision vs. recall), you might choose between these models.\n",
    "\n",
    "SVC (not tuned), while showing high precision for malignant cases, might be less reliable due to lower recall. \n",
    "In a medical context where detecting malignant cases accurately is crucial, XGBoost or Tuned SVC might be preferable due to their higher recall for malignant cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGB cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Cross-validation scores: [0.97368421 0.95614035 0.99122807 0.98245614 0.98230088]\n",
      "Mean CV accuracy: 0.9771619313771154\n",
      "Standard deviation of CV accuracy: 0.011885244147814054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define your model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'XGBoost Cross-validation scores: {cv_scores}')\n",
    "print(f'Mean CV accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Standard deviation of CV accuracy: {np.std(cv_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuned XGB cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost TUNED  Cross-validation scores: [0.96491228 0.96491228 0.99122807 0.97368421 0.97345133]\n",
      "Mean CV accuracy: 0.9736376339077782\n",
      "Standard deviation of CV accuracy: 0.009609619188189153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define your model\n",
    "xgb_model = xgb_cv\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'XGBoost TUNED  Cross-validation scores: {cv_scores}')\n",
    "print(f'Mean CV accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Standard deviation of CV accuracy: {np.std(cv_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVC cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Cross-validation scores: [0.62280702 0.62280702 0.63157895 0.63157895 0.62831858]\n",
      "Mean CV accuracy: 0.6274181027790716\n",
      "Standard deviation of CV accuracy: 0.003948679172659169\n"
     ]
    }
   ],
   "source": [
    "# Define your model\n",
    "svc_model = SVC(kernel='rbf', C=1, gamma=0.1)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(svc_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'SVC Cross-validation scores: {cv_scores}')\n",
    "print(f'Mean CV accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Standard deviation of CV accuracy: {np.std(cv_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuned SVC cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC TUNED Cross-validation scores: [0.90350877 0.93859649 0.94736842 0.93859649 0.92035398]\n",
      "Mean CV accuracy: 0.9296848315478963\n",
      "Standard deviation of CV accuracy: 0.0157720990301339\n"
     ]
    }
   ],
   "source": [
    "# Define your model\n",
    "svc_model = svc_cv\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(svc_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'SVC TUNED Cross-validation scores: {cv_scores}')\n",
    "print(f'Mean CV accuracy: {np.mean(cv_scores)}')\n",
    "print(f'Standard deviation of CV accuracy: {np.std(cv_scores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-validation results\n",
    "**Models:**\n",
    "\n",
    "XGBoost (Tuned and Not Tuned)\n",
    "SVC (Tuned and Not Tuned)\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "<u>XGBoost:</u>\n",
    "\n",
    "Both tuned and not-tuned models show excellent performance, with high mean accuracy scores and relatively low variability.\n",
    "Tuning had a minor impact on the performance of XGBoost in this case. Both versions of XGBoost are performing similarly well.\n",
    "\n",
    "<u>SVC:</u>\n",
    "\n",
    "Tuning the SVC model significantly improved its performance. The not tuned model had much lower accuracy compared to the tuned version.\n",
    "Performance variability is higher in the tuned SVC model but still maintains a good average accuracy.\n",
    "Recommendations\n",
    "XGBoost: Both versions perform well. If further improvement is needed, consider exploring additional hyperparameter tuning or advanced techniques such as feature engineering or ensemble methods.\n",
    "\n",
    "SVC: The tuned SVC model is significantly better than the not tuned version. Continue using the tuned model for its improved performance. However, be mindful of the variability in performance and consider adjusting the hyperparameters further if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall conclusion\n",
    "\n",
    "## XGBoost consistently outperformed other models, making it the preferred choice \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix\n",
    "Test:\n",
    "[[107   1]\n",
    " [  2  61]]\n",
    "\n",
    "### classification_report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.99      0.99       108\n",
    "           1       0.98      0.97      0.98        63\n",
    "\n",
    "    accuracy                           0.98       171\n",
    "   macro avg       0.98      0.98      0.98       171\n",
    "weighted avg       0.98      0.98      0.98       171"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation: \n",
    "\n",
    "scores: [0.97368421 0.95614035 0.99122807 0.98245614 0.98230088]\n",
    "\n",
    "Mean CV accuracy: 0.9771619313771154\n",
    "\n",
    "Standard deviation of CV accuracy: 0.011885244147814054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

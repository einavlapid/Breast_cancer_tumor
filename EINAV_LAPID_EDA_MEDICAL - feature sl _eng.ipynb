{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import warnings as datawarnings\n",
    "datawarnings.filterwarnings('ignore')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0      842302          1        17.99         10.38          122.80   \n",
       "1      842517          1        20.57         17.77          132.90   \n",
       "2    84300903          1        19.69         21.25          130.00   \n",
       "3    84348301          1        11.42         20.38           77.58   \n",
       "4    84358402          1        20.29         14.34          135.10   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424          1        21.56         22.39          142.00   \n",
       "565    926682          1        20.13         28.25          131.20   \n",
       "566    926954          1        16.60         28.08          108.30   \n",
       "567    927241          1        20.60         29.33          140.10   \n",
       "568     92751          0         7.76         24.54           47.92   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0       1001.0          0.11840           0.27760         0.30010   \n",
       "1       1326.0          0.08474           0.07864         0.08690   \n",
       "2       1203.0          0.10960           0.15990         0.19740   \n",
       "3        386.1          0.14250           0.28390         0.24140   \n",
       "4       1297.0          0.10030           0.13280         0.19800   \n",
       "..         ...              ...               ...             ...   \n",
       "564     1479.0          0.11100           0.11590         0.24390   \n",
       "565     1261.0          0.09780           0.10340         0.14400   \n",
       "566      858.1          0.08455           0.10230         0.09251   \n",
       "567     1265.0          0.11780           0.27700         0.35140   \n",
       "568      181.0          0.05263           0.04362         0.00000   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                0.14710  ...        25.380          17.33           184.60   \n",
       "1                0.07017  ...        24.990          23.41           158.80   \n",
       "2                0.12790  ...        23.570          25.53           152.50   \n",
       "3                0.10520  ...        14.910          26.50            98.87   \n",
       "4                0.10430  ...        22.540          16.67           152.20   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564              0.13890  ...        25.450          26.40           166.10   \n",
       "565              0.09791  ...        23.690          38.25           155.00   \n",
       "566              0.05302  ...        18.980          34.12           126.70   \n",
       "567              0.15200  ...        25.740          39.42           184.60   \n",
       "568              0.00000  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('df_cleaned.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engeeniring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new features:\n",
    "In this dataset, there are various measurements related to breast cancer diagnosis. \n",
    "\n",
    "For each type of measurement, there are three columns: mean value, worst value, and SE value.\n",
    "\n",
    "For each such set of columns, we added 4 calculated columns based on the existing three columns.\n",
    "\n",
    "The following is a detailed explanation of the 4 columns created for each measurement:\n",
    "\n",
    "\n",
    "**_mean_to_worst_ratio:**\n",
    "\n",
    "Calculation: Divides the mean of the feature by the sum of the worst-case value and a small epsilon (to avoid division by zero).\n",
    "Interpretation: This ratio indicates how much the mean deviates from the worst-case value. A higher ratio suggests that the mean is closer to the worst-case, while a lower ratio implies a larger difference.\n",
    "\n",
    "**_se_to_mean_ratio:**\n",
    "\n",
    "Calculation: Divides the standard error of the feature by the mean (plus epsilon).\n",
    "Interpretation: This ratio can be used to assess relative variability. A higher ratio indicates a larger standard error relative to the mean, suggesting more variability in the data.\n",
    "\n",
    "**_worst_mean_diff:**\n",
    "\n",
    "Calculation: Subtracts the mean from the worst-case value.\n",
    "Interpretation: This difference directly shows how much the worst-case value deviates from the average.\n",
    "\n",
    "**_z_score_worst\":**\n",
    "\n",
    "Calculation: Calculates the z-score for the worst-case value, which measures how many standard deviations away from the mean it is.\n",
    "Interpretation: A higher z-score indicates that the worst-case value is further away from the mean in terms of standard deviations.\n",
    "\n",
    "**In summary:**\n",
    "The code creates new columns in a DataFrame df2 to store these calculated metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df2 = df.copy()\n",
    "# to avoid dividing by zero add this value to the denominator\n",
    "epsilon = 1e-6\n",
    "for col in df.columns:\n",
    "    if re.search(r\"_mean\", col):    \n",
    "        first_part = col[:col.rfind('_')] if '_' in col else col\n",
    "        # This could give insight into how much the mean deviates from the extremity\n",
    "        df2[f\"{first_part}_mean_to_worst_ratio\"] = df[f\"{first_part}_mean\"]/(df[f\"{first_part}_worst\"] + epsilon)\n",
    "\n",
    "        # This ratio can indicate relative variability\n",
    "        df2[f\"{first_part}_se_to_mean_ratio\"] = df[f\"{first_part}_se\"]/(df[f\"{first_part}_mean\"] + epsilon)\n",
    "\n",
    "        # This can highlight how much the worst-case deviates from the average.\n",
    "        df2[f\"{first_part}_worst_mean_diff\"] = df[f\"{first_part}_worst\"] - df[f\"{first_part}_mean\"]\n",
    "        \n",
    "        # how many standard errors the worst-case is away from the mean\n",
    "        df2[f\"{first_part}_z_score_worst\"] = (df[f\"{first_part}_worst\"] - df[f\"{first_part}_mean\"])/ (df[f\"{first_part}_se\"]+ epsilon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**check for null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "rows_with_nulls = df2[df2.isnull().any(axis=1)]\n",
    "print(rows_with_nulls.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 70 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   radius_mean                            569 non-null    float64\n",
      " 1   texture_mean                           569 non-null    float64\n",
      " 2   perimeter_mean                         569 non-null    float64\n",
      " 3   area_mean                              569 non-null    float64\n",
      " 4   smoothness_mean                        569 non-null    float64\n",
      " 5   compactness_mean                       569 non-null    float64\n",
      " 6   concavity_mean                         569 non-null    float64\n",
      " 7   concave points_mean                    569 non-null    float64\n",
      " 8   symmetry_mean                          569 non-null    float64\n",
      " 9   fractal_dimension_mean                 569 non-null    float64\n",
      " 10  radius_se                              569 non-null    float64\n",
      " 11  texture_se                             569 non-null    float64\n",
      " 12  perimeter_se                           569 non-null    float64\n",
      " 13  area_se                                569 non-null    float64\n",
      " 14  smoothness_se                          569 non-null    float64\n",
      " 15  compactness_se                         569 non-null    float64\n",
      " 16  concavity_se                           569 non-null    float64\n",
      " 17  concave points_se                      569 non-null    float64\n",
      " 18  symmetry_se                            569 non-null    float64\n",
      " 19  fractal_dimension_se                   569 non-null    float64\n",
      " 20  radius_worst                           569 non-null    float64\n",
      " 21  texture_worst                          569 non-null    float64\n",
      " 22  perimeter_worst                        569 non-null    float64\n",
      " 23  area_worst                             569 non-null    float64\n",
      " 24  smoothness_worst                       569 non-null    float64\n",
      " 25  compactness_worst                      569 non-null    float64\n",
      " 26  concavity_worst                        569 non-null    float64\n",
      " 27  concave points_worst                   569 non-null    float64\n",
      " 28  symmetry_worst                         569 non-null    float64\n",
      " 29  fractal_dimension_worst                569 non-null    float64\n",
      " 30  radius_mean_to_worst_ratio             569 non-null    float64\n",
      " 31  radius_se_to_mean_ratio                569 non-null    float64\n",
      " 32  radius_worst_mean_diff                 569 non-null    float64\n",
      " 33  radius_z_score_worst                   569 non-null    float64\n",
      " 34  texture_mean_to_worst_ratio            569 non-null    float64\n",
      " 35  texture_se_to_mean_ratio               569 non-null    float64\n",
      " 36  texture_worst_mean_diff                569 non-null    float64\n",
      " 37  texture_z_score_worst                  569 non-null    float64\n",
      " 38  perimeter_mean_to_worst_ratio          569 non-null    float64\n",
      " 39  perimeter_se_to_mean_ratio             569 non-null    float64\n",
      " 40  perimeter_worst_mean_diff              569 non-null    float64\n",
      " 41  perimeter_z_score_worst                569 non-null    float64\n",
      " 42  area_mean_to_worst_ratio               569 non-null    float64\n",
      " 43  area_se_to_mean_ratio                  569 non-null    float64\n",
      " 44  area_worst_mean_diff                   569 non-null    float64\n",
      " 45  area_z_score_worst                     569 non-null    float64\n",
      " 46  smoothness_mean_to_worst_ratio         569 non-null    float64\n",
      " 47  smoothness_se_to_mean_ratio            569 non-null    float64\n",
      " 48  smoothness_worst_mean_diff             569 non-null    float64\n",
      " 49  smoothness_z_score_worst               569 non-null    float64\n",
      " 50  compactness_mean_to_worst_ratio        569 non-null    float64\n",
      " 51  compactness_se_to_mean_ratio           569 non-null    float64\n",
      " 52  compactness_worst_mean_diff            569 non-null    float64\n",
      " 53  compactness_z_score_worst              569 non-null    float64\n",
      " 54  concavity_mean_to_worst_ratio          569 non-null    float64\n",
      " 55  concavity_se_to_mean_ratio             569 non-null    float64\n",
      " 56  concavity_worst_mean_diff              569 non-null    float64\n",
      " 57  concavity_z_score_worst                569 non-null    float64\n",
      " 58  concave points_mean_to_worst_ratio     569 non-null    float64\n",
      " 59  concave points_se_to_mean_ratio        569 non-null    float64\n",
      " 60  concave points_worst_mean_diff         569 non-null    float64\n",
      " 61  concave points_z_score_worst           569 non-null    float64\n",
      " 62  symmetry_mean_to_worst_ratio           569 non-null    float64\n",
      " 63  symmetry_se_to_mean_ratio              569 non-null    float64\n",
      " 64  symmetry_worst_mean_diff               569 non-null    float64\n",
      " 65  symmetry_z_score_worst                 569 non-null    float64\n",
      " 66  fractal_dimension_mean_to_worst_ratio  569 non-null    float64\n",
      " 67  fractal_dimension_se_to_mean_ratio     569 non-null    float64\n",
      " 68  fractal_dimension_worst_mean_diff      569 non-null    float64\n",
      " 69  fractal_dimension_z_score_worst        569 non-null    float64\n",
      "dtypes: float64(70)\n",
      "memory usage: 311.3 KB\n"
     ]
    }
   ],
   "source": [
    "y = df2['diagnosis']\n",
    "X = df2.drop(columns=['diagnosis', 'id'])\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "\n",
    "## Multivariable feature selection\n",
    "\n",
    "At this stage, I want to filter out columns that do not contribute and reach 30 columns out of 70 \n",
    "\n",
    "using multivariable selection with the following models: \n",
    "\n",
    "Lasso, Ridge, SVM, GradientBoost, RandomForest, XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Feature  Lasso  Ridge  SVC  GradientBoost  \\\n",
      "13                     area_se      1      1    1              1   \n",
      "3                    area_mean      1      1    1              1   \n",
      "21               texture_worst      1      1    1              1   \n",
      "22             perimeter_worst      1      1    1              1   \n",
      "44        area_worst_mean_diff      1      1    1              1   \n",
      "..                         ...    ...    ...  ...            ...   \n",
      "28              symmetry_worst      0      1    0              1   \n",
      "29     fractal_dimension_worst      0      1    0              1   \n",
      "30  radius_mean_to_worst_ratio      0      1    0              0   \n",
      "65      symmetry_z_score_worst      0      1    0              0   \n",
      "33        radius_z_score_worst      0      1    0              0   \n",
      "\n",
      "    RandomForest  Xgb  Sum  \n",
      "13             1    1    6  \n",
      "3              1    1    6  \n",
      "21             1    1    6  \n",
      "22             1    1    6  \n",
      "44             1    1    6  \n",
      "..           ...  ...  ...  \n",
      "28             1    0    3  \n",
      "29             1    0    3  \n",
      "30             1    1    3  \n",
      "65             1    0    2  \n",
      "33             1    0    2  \n",
      "\n",
      "[70 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Fit models and determine if a feature is selected (1) or not (0)\n",
    "lasso = Lasso(alpha=0.01).fit(X, y)\n",
    "lasso_selected = (np.abs(lasso.coef_) > 0).astype(int)\n",
    "\n",
    "ridge = Ridge(alpha=1.0).fit(X, y)\n",
    "ridge_selected = (np.abs(ridge.coef_) > 0).astype(int)\n",
    "\n",
    "svc = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42).fit(X,y)\n",
    "results = permutation_importance(svc, X, y, scoring='accuracy')\n",
    "svc_selected = (results.importances_mean > 0).astype(int)\n",
    "\n",
    "gb = GradientBoostingClassifier().fit(X, y)\n",
    "gb_selected = (gb.feature_importances_ > 0).astype(int)\n",
    "\n",
    "rf = RandomForestClassifier().fit(X, y)\n",
    "rf_selected = (rf.feature_importances_ > 0).astype(int)\n",
    "\n",
    "xgb = xgb.XGBClassifier().fit(X, y)\n",
    "xgb_selected = (xgb.feature_importances_ > 0) .astype(int)\n",
    "\n",
    "# Create a DataFrame to store results\n",
    "selection_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Lasso': lasso_selected,\n",
    "    'Ridge': ridge_selected,\n",
    "    'SVC': svc_selected,\n",
    "    'GradientBoost': gb_selected,\n",
    "    'RandomForest': rf_selected,\n",
    "    'Xgb': xgb_selected,\n",
    "    \n",
    "})\n",
    "\n",
    "# Sum the number of selections for each feature\n",
    "selection_df['Sum'] = selection_df[['Lasso', 'Ridge', 'SVC', 'GradientBoost', 'RandomForest', 'Xgb'\n",
    "                                   ]].sum(axis=1)\n",
    "\n",
    "selection_df = selection_df.sort_values(by='Sum', ascending=False)\n",
    "print(selection_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "More or equal 5, total columns: 12\n",
      "\n",
      "['area_se', 'area_mean', 'texture_worst', 'perimeter_worst', 'area_worst_mean_diff', 'area_worst', 'fractal_dimension_z_score_worst', 'perimeter_mean', 'texture_mean', 'texture_worst_mean_diff', 'perimeter_worst_mean_diff', 'perimeter_se']\n",
      "\n",
      "More or equal 4, total columns: 47\n",
      "\n",
      "['area_se', 'area_mean', 'texture_worst', 'perimeter_worst', 'area_worst_mean_diff', 'area_worst', 'fractal_dimension_z_score_worst', 'perimeter_mean', 'texture_mean', 'texture_worst_mean_diff', 'perimeter_worst_mean_diff', 'perimeter_se', 'smoothness_mean_to_worst_ratio', 'area_se_to_mean_ratio', 'smoothness_worst_mean_diff', 'area_mean_to_worst_ratio', 'texture_z_score_worst', 'smoothness_se_to_mean_ratio', 'compactness_z_score_worst', 'smoothness_z_score_worst', 'radius_worst_mean_diff', 'concavity_mean_to_worst_ratio', 'concavity_se_to_mean_ratio', 'concavity_worst_mean_diff', 'concavity_z_score_worst', 'concave points_mean_to_worst_ratio', 'concave points_se_to_mean_ratio', 'concave points_worst_mean_diff', 'concave points_z_score_worst', 'symmetry_se_to_mean_ratio', 'fractal_dimension_se_to_mean_ratio', 'texture_mean_to_worst_ratio', 'radius_mean', 'compactness_worst', 'smoothness_worst', 'texture_se', 'radius_se', 'fractal_dimension_mean', 'concave points_se', 'concave points_mean', 'radius_worst', 'concavity_mean', 'smoothness_se', 'concavity_worst', 'concave points_worst', 'compactness_mean', 'smoothness_mean']\n",
      "\n",
      "less then 3, total columns: 2\n",
      "\n",
      "['symmetry_z_score_worst', 'radius_z_score_worst']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "more_than_5 = selection_df[selection_df['Sum'] >= 5]['Feature'].tolist()\n",
    "print(f\"\\nMore or equal 5, total columns: {len(more_than_5)}\\n\")\n",
    "print(more_than_5)\n",
    "more_than_4 = selection_df[selection_df['Sum'] >= 4]['Feature'].tolist()\n",
    "print(f\"\\nMore or equal 4, total columns: {len(more_than_4)}\\n\")\n",
    "print(more_than_4)\n",
    "\n",
    "less_then_3 = selection_df[selection_df['Sum'] < 3]['Feature'].tolist()\n",
    "print(f\"\\nless then 3, total columns: {len(less_then_3)}\\n\")\n",
    "print(less_then_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariable feature selection - results\n",
    "\n",
    "The models consistently favored the original features.\n",
    "\n",
    "<u>More or equal 5:</u>\n",
    "This category contains 11 columns that have a score of 5 or higher, indicating they are considered relatively important.\n",
    "\n",
    "<u>More or equal 4:</u> This category contains 48 columns with a score of 4 or higher, including those from the previous category.\n",
    " \n",
    "**The goal of reducing the number of columns to 30 has not been achieved using this method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "## Univariable feature selection\n",
    "Given the inability to reduce the feature set to 30 columns using the previous method,\n",
    "we will explore a univariate approach where each feature's relationship with the target variable is assessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution of each column\n",
    "\n",
    "Since this method examines each column individually in relation to the target column, we must first assess the distribution of each column. \n",
    "Based on the distribution, we will employ the appropriate statistical test. \n",
    "\n",
    "For columns with a <u>**normal distribution, we will use a t-test.**</u>\n",
    "\n",
    "For columns with a <u>**non-normal distribution, we will use the Wilcoxon Rank-Sum test.**</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total parametric columns:11\n",
      "\n",
      "\n",
      "total nonparametric columns:59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skewness_values = X.skew()\n",
    "para_columns = skewness_values[abs(skewness_values) <= 0.5].index.tolist()\n",
    "print(f\"\\ntotal parametric columns:{len(para_columns)}\\n\")\n",
    "non_para_columns = skewness_values[abs(skewness_values) > 0.5].index.tolist()\n",
    "print(f\"\\ntotal nonparametric columns:{len(non_para_columns)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametric t-test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Test Results sorted by P-value:\n",
      "                                  Feature  T-statistic        P-value\n",
      "3                    concave points_worst   -31.054555  1.969100e-124\n",
      "7          concave points_worst_mean_diff   -19.849779   5.681090e-67\n",
      "6      concave points_mean_to_worst_ratio   -13.836209   1.010847e-37\n",
      "10  fractal_dimension_mean_to_worst_ratio    13.647337   7.155977e-37\n",
      "1                           texture_worst   -12.230981   1.078057e-30\n",
      "2                        smoothness_worst   -11.066747   6.575144e-26\n",
      "0                         smoothness_mean    -9.146099   1.051850e-18\n",
      "8            concave points_z_score_worst    -6.716225   4.541915e-11\n",
      "9            symmetry_mean_to_worst_ratio     5.110660   4.394815e-07\n",
      "5          smoothness_mean_to_worst_ratio     4.588244   5.506764e-06\n",
      "4             texture_mean_to_worst_ratio     4.115146   4.443689e-05\n",
      "\n",
      "P-value) > 0.05: \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>T-statistic</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Feature, T-statistic, P-value]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "results = []\n",
    "# Step 2: Perform t-tests for each feature\n",
    "for column in para_columns:\n",
    "    group1 = X[column][y == 0]  # Group 0 (benign)\n",
    "    group2 = X[column][y == 1]  # Group 1 (malignant)\n",
    "    \n",
    "    # Perform independent t-test\n",
    "    t_statistic, p_value = stats.ttest_ind(group1, group2)\n",
    "    \n",
    "    # Append results to the DataFrame\n",
    "    results.append({'Feature': column, 'T-statistic': t_statistic, 'P-value': p_value})\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "sorted_features = results_df.sort_values(by='P-value')\n",
    "\n",
    "# Step 3: Display the results\n",
    "print(\"T-Test Results sorted by P-value:\")\n",
    "print(sorted_features)\n",
    "\n",
    "print(\"\\nP-value) > 0.05: \\n \")\n",
    "results_df[(results_df['P-value'] > 0.05)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nonparametric Wilcoxon Rank-Sum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon Rank-Sum Test Results sorted by P-value:\n",
      "                               Feature  Statistic       P-value\n",
      "20                     perimeter_worst -18.978444  2.570996e-80\n",
      "19                        radius_worst -18.778554  1.131190e-78\n",
      "21                          area_worst -18.754029  1.794645e-78\n",
      "6                  concave points_mean -18.538845  1.003546e-76\n",
      "39                area_worst_mean_diff -18.516693  1.514588e-76\n",
      "35           perimeter_worst_mean_diff -18.010904  1.599948e-72\n",
      "2                       perimeter_mean -17.838703  3.538114e-71\n",
      "28              radius_worst_mean_diff -17.650153  1.014809e-69\n",
      "3                            area_mean -17.496148  1.532915e-68\n",
      "5                       concavity_mean -17.476634  2.158718e-68\n",
      "0                          radius_mean -17.464240  2.682507e-68\n",
      "12                             area_se -17.020949  5.743236e-65\n",
      "23                     concavity_worst -16.819477  1.757032e-63\n",
      "52     concave points_se_to_mean_ratio  16.293382  1.099756e-59\n",
      "49          concavity_se_to_mean_ratio  15.873561  9.660107e-57\n",
      "33       perimeter_mean_to_worst_ratio  15.361443  2.968940e-53\n",
      "37            area_mean_to_worst_ratio  15.290769  8.810339e-53\n",
      "26          radius_mean_to_worst_ratio  15.289187  9.027008e-53\n",
      "50           concavity_worst_mean_diff -15.044995  3.723643e-51\n",
      "11                        perimeter_se -15.024425  5.079991e-51\n",
      "9                            radius_se -14.702703  6.193694e-49\n",
      "4                     compactness_mean -14.521009  8.918725e-48\n",
      "22                   compactness_worst -14.461939  2.107752e-47\n",
      "46         compactness_worst_mean_diff -13.341449  1.328514e-40\n",
      "16                   concave points_se -11.647397  2.365738e-31\n",
      "15                        concavity_se -11.209381  3.667508e-29\n",
      "1                         texture_mean -11.010018  3.419341e-28\n",
      "57   fractal_dimension_worst_mean_diff -10.844674  2.113875e-27\n",
      "24                      symmetry_worst  -9.457841  3.143677e-21\n",
      "38               area_se_to_mean_ratio  -9.387431  6.148147e-21\n",
      "27             radius_se_to_mean_ratio  -9.195453  3.734194e-20\n",
      "14                      compactness_se  -9.072302  1.165291e-19\n",
      "48       concavity_mean_to_worst_ratio  -8.961808  3.193964e-19\n",
      "40                  area_z_score_worst  -8.947041  3.651391e-19\n",
      "34          perimeter_se_to_mean_ratio  -8.846305  9.046488e-19\n",
      "29                radius_z_score_worst  -8.797255  1.402029e-18\n",
      "58     fractal_dimension_z_score_worst  -8.694937  3.470215e-18\n",
      "36             perimeter_z_score_worst  -8.594201  8.384593e-18\n",
      "31             texture_worst_mean_diff  -8.484763  2.161588e-17\n",
      "51             concavity_z_score_worst  -8.437560  3.240321e-17\n",
      "47           compactness_z_score_worst  -8.435977  3.284466e-17\n",
      "43            smoothness_z_score_worst  -8.026177  1.005571e-15\n",
      "7                        symmetry_mean  -7.925969  2.263749e-15\n",
      "42          smoothness_worst_mean_diff  -7.865316  3.681670e-15\n",
      "32               texture_z_score_worst  -7.850548  4.142220e-15\n",
      "54            symmetry_worst_mean_diff  -7.762734  8.311777e-15\n",
      "55              symmetry_z_score_worst  -7.724497  1.122962e-14\n",
      "25             fractal_dimension_worst  -7.423344  1.142000e-13\n",
      "53           symmetry_se_to_mean_ratio   6.180230  6.400821e-10\n",
      "44     compactness_mean_to_worst_ratio   5.968210  2.398705e-09\n",
      "56  fractal_dimension_se_to_mean_ratio  -5.549444  2.865799e-08\n",
      "41         smoothness_se_to_mean_ratio   5.326875  9.991671e-08\n",
      "30            texture_se_to_mean_ratio   4.980365  6.346456e-07\n",
      "18                fractal_dimension_se  -4.802099  1.570110e-06\n",
      "45        compactness_se_to_mean_ratio   3.531033  4.139406e-04\n",
      "17                         symmetry_se   2.199841  2.781816e-02\n",
      "13                       smoothness_se   1.243904  2.135347e-01\n",
      "8               fractal_dimension_mean   0.617337  5.370122e-01\n",
      "10                          texture_se  -0.462805  6.435040e-01\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ranksums\n",
    "# Step 1: Prepare to hold the results for the Wilcoxon rank-sum test\n",
    "results = []\n",
    "\n",
    "# Step 2: Perform the Wilcoxon rank-sum test for each feature\n",
    "for column in non_para_columns:\n",
    "    group1 = X[column][y == 0]  # Benign group\n",
    "    group2 = X[column][y == 1]  # Malignant group\n",
    "    \n",
    "    # Perform the Wilcoxon rank-sum test\n",
    "    stat, p_value = ranksums(group1, group2)\n",
    "    \n",
    "    # Append results to the list\n",
    "    results.append({'Feature': column, 'Statistic': stat, 'P-value': p_value})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "sorted_features = results_df.copy().sort_values(by='P-value')\n",
    "print(\"Wilcoxon Rank-Sum Test Results sorted by P-value:\")\n",
    "print(sorted_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### univariable feature selection - results\n",
    "<u>engineered features:</u> \n",
    "\n",
    "Our univariate analysis showed that the engineered features did not improve the model's ability to classify the target variable as effectively as the original features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              569 non-null    float64\n",
      " 1   texture_mean             569 non-null    float64\n",
      " 2   perimeter_mean           569 non-null    float64\n",
      " 3   area_mean                569 non-null    float64\n",
      " 4   smoothness_mean          569 non-null    float64\n",
      " 5   compactness_mean         569 non-null    float64\n",
      " 6   concavity_mean           569 non-null    float64\n",
      " 7   concave points_mean      569 non-null    float64\n",
      " 8   symmetry_mean            569 non-null    float64\n",
      " 9   fractal_dimension_mean   569 non-null    float64\n",
      " 10  radius_se                569 non-null    float64\n",
      " 11  texture_se               569 non-null    float64\n",
      " 12  perimeter_se             569 non-null    float64\n",
      " 13  area_se                  569 non-null    float64\n",
      " 14  smoothness_se            569 non-null    float64\n",
      " 15  compactness_se           569 non-null    float64\n",
      " 16  concavity_se             569 non-null    float64\n",
      " 17  concave points_se        569 non-null    float64\n",
      " 18  symmetry_se              569 non-null    float64\n",
      " 19  fractal_dimension_se     569 non-null    float64\n",
      " 20  radius_worst             569 non-null    float64\n",
      " 21  texture_worst            569 non-null    float64\n",
      " 22  perimeter_worst          569 non-null    float64\n",
      " 23  area_worst               569 non-null    float64\n",
      " 24  smoothness_worst         569 non-null    float64\n",
      " 25  compactness_worst        569 non-null    float64\n",
      " 26  concavity_worst          569 non-null    float64\n",
      " 27  concave points_worst     569 non-null    float64\n",
      " 28  symmetry_worst           569 non-null    float64\n",
      " 29  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "# To avoid dividing by zero add this value to the denominator\n",
    "df2 = df2.drop(columns=['id'])\n",
    "y = df2['diagnosis']\n",
    "X = df2.drop(columns=['diagnosis'])\n",
    "X.info()                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving to pick file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    int8   \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int8(1)\n",
      "memory usage: 134.0 KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_pickle('df_final_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In summary\n",
    "\n",
    "removed the 'id' column as it was not relevant for prediction.\n",
    "\n",
    "removed calculated columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**started with 32 original columns**\n",
    "**we are left with 31 columns for model building.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
